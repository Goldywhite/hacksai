{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fdee3c-8481-4cdd-843a-038162589170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b339bd8-0ff0-45a7-bc08-f5edb278280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468c4e17-8214-4ca4-a05d-e7082d6da76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MASKS_PATH = 'datasets/train_updated_titiles/masks/train_mask_{num:03d}.png'\n",
    "IMAGES_PATH = 'datasets/train_updated_titiles/images/train_image_{num:03d}.png'\n",
    "data = []\n",
    "total_area = 0\n",
    "for num in range(0,21):\n",
    "    im_file = IMAGES_PATH.format(num=num)\n",
    "    mask_file = MASKS_PATH.format(num=num)\n",
    "    file_name = os.path.basename(im_file)\n",
    "    im_cv = np.array(Image.open(im_file))\n",
    "    if im_cv.shape[2] != 3:\n",
    "        im_cv = im_cv[:,:,:3]\n",
    "    mask_cv = np.array(Image.open(mask_file))\n",
    "    print(num, im_cv.shape, mask_cv.shape)\n",
    "    data.append((im_cv, mask_cv))\n",
    "    total_area += im_cv.shape[0]*im_cv.shape[1]\n",
    "\n",
    "for i, (img, mask) in enumerate(data):\n",
    "    area = img.shape[0]*img.shape[1]\n",
    "    percent = area / total_area\n",
    "    data[i] += (percent,)\n",
    "    print(img.shape[:2], percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b986e57a-c5aa-45a3-88a7-2cd64a6c82a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def random_crop(img, mask, size):\n",
    "    half_size = size // 2\n",
    "    d = half_size * 2**0.5\n",
    "    angle = np.random.randint(360)\n",
    "    rad =  np.pi * angle / 180\n",
    "    dist = int(np.ceil(d * max(abs(np.cos(np.pi/4 - rad)), abs(np.sin(np.pi/4 - rad)))))\n",
    "    angle, rad, dist\n",
    "    dist = dist + 1\n",
    "    x = np.random.randint(dist, img.shape[1] - dist)\n",
    "    y = np.random.randint(dist, img.shape[0] - dist)\n",
    "    area = img[y-dist:y+dist, x-dist:x+dist, :]\n",
    "    area_mask = mask[y-dist:y+dist, x-dist:x+dist]\n",
    "    \n",
    "    (h, w) = area.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "    rotated = cv2.warpAffine(area, M, (w, h))\n",
    "    rotated_mask = cv2.warpAffine(area_mask, M, (w, h))\n",
    "    cropped = rotated[cY-half_size:cY+half_size, cX-half_size:cX+half_size,:]\n",
    "    cropped_mask = rotated_mask[cY-half_size:cY+half_size, cX-half_size:cX+half_size]\n",
    "    return cropped, cropped_mask\n",
    "\n",
    "\n",
    "def get_batch(length, size, min_percent = 0):\n",
    "    res_x = []\n",
    "    res_y = []\n",
    "    limit = size * size * min_percent\n",
    "    for img, mask, percent in data:\n",
    "        for i in range(int(round(length * percent))):\n",
    "            while True:\n",
    "                cropped, cropped_mask = random_crop(img, mask, size)\n",
    "                if cropped_mask.sum() > limit:\n",
    "                    break\n",
    "            res_x.append(cropped)\n",
    "            res_y.append(cropped_mask)\n",
    "    res_x = np.array(res_x)\n",
    "    res_y = np.array(res_y)\n",
    "    res_y = res_y.reshape(res_y.shape + (1,))\n",
    "    return res_x, res_y\n",
    "        \n",
    "\n",
    "cnt = len(data)\n",
    "fig, axes = plt.subplots(cnt, 2, figsize=(10,5*cnt))\n",
    "for (img, mask, percent), (ax_img, ax_mask) in zip([data[4]]*cnt, axes):\n",
    "    cropped, cropped_mask = random_crop(img, mask, 512)\n",
    "    ax_img.imshow(cropped)\n",
    "    ax_mask.imshow(cropped_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d262431-5ff8-4bf5-a266-a990f0797dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda.amp as amp\n",
    "\n",
    "\n",
    "## Soft Dice Loss for binary segmentation\n",
    "##\n",
    "# v1: pytorch autograd\n",
    "class SoftDiceLossV1(nn.Module):\n",
    "    '''\n",
    "    soft-dice loss, useful in binary segmentation\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 p=1,\n",
    "                 smooth=1):\n",
    "        super(SoftDiceLossV1, self).__init__()\n",
    "        self.p = p\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        '''\n",
    "        inputs:\n",
    "            logits: tensor of shape (N, H, W, ...)\n",
    "            label: tensor of shape(N, H, W, ...)\n",
    "        output:\n",
    "            loss: tensor of shape(1, )\n",
    "        '''\n",
    "        probs = torch.sigmoid(logits)\n",
    "        numer = (probs * labels).sum()\n",
    "        denor = (probs.pow(self.p) + labels.pow(self.p)).sum()\n",
    "        loss = 1. - (2 * numer + self.smooth) / (denor + self.smooth)\n",
    "        return loss\n",
    "\n",
    "\n",
    "##\n",
    "# v2: self-derived grad formula\n",
    "class SoftDiceLossV2(nn.Module):\n",
    "    '''\n",
    "    soft-dice loss, useful in binary segmentation\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 p=1,\n",
    "                 smooth=1):\n",
    "        super(SoftDiceLossV2, self).__init__()\n",
    "        self.p = p\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        '''\n",
    "        inputs:\n",
    "            logits: tensor of shape (N, H, W, ...)\n",
    "            label: tensor of shape(N, H, W, ...)\n",
    "        output:\n",
    "            loss: tensor of shape(1, )\n",
    "        '''\n",
    "        logits = logits.view(1, -1)\n",
    "        labels = labels.view(1, -1)\n",
    "        loss = SoftDiceLossV2Func.apply(logits, labels, self.p, self.smooth)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class SoftDiceLossV2Func(torch.autograd.Function):\n",
    "    '''\n",
    "    compute backward directly for better numeric stability\n",
    "    '''\n",
    "    @staticmethod\n",
    "    @amp.custom_fwd(cast_inputs=torch.float32)\n",
    "    def forward(ctx, logits, labels, p, smooth):\n",
    "        '''\n",
    "        inputs:\n",
    "            logits: (N, L)\n",
    "            labels: (N, L)\n",
    "        outpus:\n",
    "            loss: (N,)\n",
    "        '''\n",
    "        #  logits = logits.float()\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        numer = 2 * (probs * labels).sum(dim=1) + smooth\n",
    "        denor = (probs.pow(p) + labels.pow(p)).sum(dim=1) + smooth\n",
    "        loss = 1. - numer / denor\n",
    "\n",
    "        ctx.vars = probs, labels, numer, denor, p, smooth\n",
    "        return loss\n",
    "\n",
    "    @staticmethod\n",
    "    @amp.custom_bwd\n",
    "    def backward(ctx, grad_output):\n",
    "        '''\n",
    "        compute gradient of soft-dice loss\n",
    "        '''\n",
    "        probs, labels, numer, denor, p, smooth = ctx.vars\n",
    "\n",
    "        numer, denor = numer.view(-1, 1), denor.view(-1, 1)\n",
    "\n",
    "        term1 = (1. - probs).mul_(2).mul_(labels).mul_(probs).div_(denor)\n",
    "\n",
    "        term2 = probs.pow(p).mul_(1. - probs).mul_(numer).mul_(p).div_(denor.pow_(2))\n",
    "\n",
    "        grads = term2.sub_(term1).mul_(grad_output)\n",
    "\n",
    "        return grads, None, None, None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86a499-6f46-4d40-a671-30df1fa8dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDiceLoss(nn.Module):\n",
    "    \"\"\"Soft Dice loss of binary class\n",
    "    Args:\n",
    "        p: Denominator value: \\sum{x^p} + \\sum{y^p}, default: 2\n",
    "        predict: A tensor of shape [N, *]\n",
    "        target: A tensor of shape same with predict\n",
    "       Returns:\n",
    "        Loss tensor\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p=2, epsilon=1e-6):\n",
    "        super().__init__()\n",
    "        self.p = p  # pow degree\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, predict, target):\n",
    "        predict = predict.flatten(1)\n",
    "        target = target.flatten(1)\n",
    "\n",
    "        # https://pytorch.org/docs/stable/generated/torch.mul.html\n",
    "        num = torch.sum(torch.mul(predict, target), dim=1) + self.epsilon\n",
    "        den = torch.sum(predict.pow(self.p) + target.pow(self.p), dim=1) + self.epsilon\n",
    "        loss = 1 - 2 * num / den\n",
    "\n",
    "        return loss.mean()  # over batch\n",
    "\n",
    "#PyTorch\n",
    "class IoULoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(IoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #intersection is equivalent to True Positive count\n",
    "        #union is the mutually inclusive area of all labels & predictions \n",
    "        intersection = (inputs * targets).sum()\n",
    "        total = (inputs + targets).sum()\n",
    "        union = total - intersection \n",
    "        \n",
    "        IoU = (intersection + smooth)/(union + smooth)\n",
    "                \n",
    "        return 1 - IoU\n",
    "\n",
    "\n",
    "#PyTorch\n",
    "ALPHA = 0.5\n",
    "BETA = 0.5\n",
    "\n",
    "class TverskyLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(TverskyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = (inputs * targets).sum()    \n",
    "        FP = ((1-targets) * inputs).sum()\n",
    "        FN = (targets * (1-inputs)).sum()\n",
    "       \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        \n",
    "        return 1 - Tversky\n",
    "\n",
    "class MiniUnet(nn.Module):\n",
    "    def __init__(self, first_size=64):\n",
    "        super().__init__()\n",
    "        self.block1 = self.block(3, first_size) #64\n",
    "        self.block2 = self.block(first_size, first_size*2) #128\n",
    "        self.block3 = self.block(first_size*2, first_size*4) #256\n",
    "        self.block4 = self.block(first_size*4, first_size*8) #512\n",
    "        \n",
    "        self.block5 = self.block(first_size*8, first_size*4)\n",
    "        self.block6 = self.block(first_size*4, first_size*2)\n",
    "        self.block7 = self.block(first_size*2, first_size)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.up1 = self.up(first_size*8)\n",
    "        self.up2 = self.up(first_size*4)\n",
    "        self.up3 = self.up(first_size*2)\n",
    "        self.conv = nn.Conv2d(first_size, 1, kernel_size=1, bias=False)\n",
    "        #self.up1 = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        # Your code here\n",
    "\n",
    "    def block(self, in_channels, out_channels):\n",
    "      return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "      \n",
    "    def up(self, in_channels):\n",
    "        return nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "      # return nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def cat(self, out_up, out_down):\n",
    "        return torch.cat((out_up, out_down), dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pad = (0, (16 - x.shape[3] % 16) % 16, 0, (16 - x.shape[2] % 16) % 16)\n",
    "        if sum(pad) > 0:\n",
    "            print(x.shape)\n",
    "            print(pad)\n",
    "            x = F.pad(input=x, pad=pad, mode='constant', value=0.0)\n",
    "            print(x.shape)\n",
    "\n",
    "        out1 = self.block1(x) #  ------------------------------>\n",
    "        out_pool1 = self.pool(out1)\n",
    "        \n",
    "        out2 = self.block2(out_pool1)\n",
    "        out_pool2 = self.pool(out2)\n",
    "        \n",
    "        out3 = self.block3(out_pool2)\n",
    "        out_pool3 = self.pool(out3)\n",
    "        \n",
    "        out4 = self.block4(out_pool3)\n",
    "        # return up\n",
    "        \n",
    "        out_up1 = self.up1(out4)\n",
    "        out_cat1 = self.cat(out_up1, out3)\n",
    "        out5 = self.block5(out_cat1)\n",
    "        \n",
    "        out_up2 = self.up2(out5)\n",
    "        out_cat2 = self.cat(out_up2, out2)\n",
    "        out6 = self.block6(out_cat2)\n",
    "        \n",
    "        out_up3 = self.up3(out6)\n",
    "        out_cat3 = self.cat(out_up3, out1) # <-------\n",
    "        out7 = self.block7(out_cat3)\n",
    "        \n",
    "        out = self.conv(out7)\n",
    "        return out\n",
    "\n",
    "class MaxiUnet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, first_size=64, layers=4):\n",
    "        b = 64\n",
    "        super().__init__()\n",
    "        forward_blocks = [self.block(in_channels, first_size)]\n",
    "        backward_blocks = []\n",
    "        upscale_blocks = []\n",
    "        size = first_size\n",
    "        for i in range(1, layers):\n",
    "            block = self.block(size, size * 2)\n",
    "            forward_blocks.append(block)\n",
    "            block = self.block(size * 2, size)\n",
    "            backward_blocks.append(block)\n",
    "            size *= 2\n",
    "            block = self.up(size)\n",
    "            upscale_blocks.append(block)\n",
    "        forward_blocks[-1].use_pool = False\n",
    "        backward_blocks.reverse()\n",
    "        upscale_blocks.reverse()\n",
    "        self.forward_blocks = nn.ModuleList(forward_blocks)\n",
    "        self.backward_blocks = nn.ModuleList(backward_blocks)\n",
    "        self.upscale_blocks = nn.ModuleList(upscale_blocks)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.out_block = nn.Conv2d(first_size, out_channels, kernel_size=1, bias=False)\n",
    "\n",
    "    def block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        block.use_pool = True\n",
    "        return block\n",
    "      \n",
    "    def up(self, in_channels):\n",
    "        return nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "    def cat(self, out_up, out_down):\n",
    "        return torch.cat((out_up, out_down), dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for block in self.forward_blocks:\n",
    "            x = block(x)\n",
    "            outs.append(x)\n",
    "            if block.use_pool:\n",
    "                x = self.pool(x)\n",
    "        outs.pop()\n",
    "        outs.reverse()\n",
    "        for out, block, up in zip(outs, self.backward_blocks, self.upscale_blocks):\n",
    "            x = up(x)\n",
    "            cat = self.cat(x, out)\n",
    "            x = block(cat)\n",
    "        return self.out_block(x)\n",
    "\n",
    "model = MaxiUnet(first_size=112, layers=5, out_channels=1)\n",
    "with open('weights_5_112.pkl', 'rb') as f:\n",
    "    model.load_state_dict(pickle.load(f))\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de37d864-a58d-44cd-9946-3365e1459fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "criterion = SoftDiceLossV1()\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717befc2-2fca-4ffe-acfd-69ab0ee8ae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train()\n",
    "\n",
    "QUOTA = 1024 * 1024\n",
    "epochs = 50\n",
    "metric = BinaryF1Score()\n",
    "metric.to(device)\n",
    "\n",
    "batch_count = 10\n",
    "for size in (128, 256, 512, 1024):\n",
    "    batch_size = QUOTA // size // size\n",
    "    \n",
    "    \n",
    "    train_x, train_y = get_batch(batch_size * batch_count, size)\n",
    "    train_x = train_x / 255\n",
    "    for epoch in range(1, epochs+1):\n",
    "        ep_loss = 0\n",
    "        outputs = []\n",
    "        xs = []\n",
    "        count = 0\n",
    "        for batch_num in range(batch_count):\n",
    "            x = torch.tensor(train_x[batch_num*batch_size:(batch_num+1)*batch_size, :, :, :], dtype=torch.float, device=device)\n",
    "            y = torch.tensor(train_y[batch_num*batch_size:(batch_num+1)*batch_size, :, :, :], dtype=torch.float, device=device)\n",
    "            x = x.permute(0, 3,1,2)\n",
    "            y = y.permute(0, 3,1,2)\n",
    "            batch_x = x\n",
    "            batch_y = y\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_x)\n",
    "            loss = criterion(output.squeeze(1), batch_y.squeeze(1))\n",
    "            loss.backward()\n",
    "            \n",
    "            outputs.append(output.detach())\n",
    "            ep_loss += loss.item()\n",
    "            count += 1\n",
    "            optimizer.step()\n",
    "        outputs = torch.cat(outputs)\n",
    "        print(f\"Epoch {epoch}: loss={ep_loss/count}, f1score={metric(outputs, torch.tensor(train_y, device=device).permute(0,3,1,2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239ccd2-9098-42a7-ba7d-b90a7831a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "QUOTA = 1024 * 1024\n",
    "epochs = 50\n",
    "metric = BinaryF1Score()\n",
    "metric.to(device)\n",
    "for size in (128, 256):\n",
    "    batch_size = QUOTA // size // size\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_x, train_y = get_batch(batch_size, size)\n",
    "        train_x = train_x / 255\n",
    "        x = torch.tensor(train_x, dtype=torch.float, device=device)\n",
    "        y = torch.tensor(train_y, dtype=torch.float, device=device)\n",
    "        x = x.permute(0, 3,1,2)\n",
    "        y = y.permute(0, 3,1,2)\n",
    "        batch_x = x\n",
    "        batch_y = y\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        loss = criterion(output.squeeze(1), batch_y.squeeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch}: loss={loss.item()}, f1score={metric(output, torch.tensor(train_y, device=device).permute(0,3,1,2))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecec2f6-f99b-4bc0-9ea7-cdd83d0c858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = min(10, x.shape[0])\n",
    "indeces = np.arange(x.shape[0])\n",
    "np.random.shuffle(indeces)\n",
    "indeces = indeces[:cnt]\n",
    "\n",
    "fig, axes = plt.subplots(cnt, 4, figsize=(20,5 * cnt))\n",
    "plot_x = train_x\n",
    "plot_y = train_y\n",
    "plot_y = plot_y.reshape(plot_y.shape[:3])\n",
    "plot_p = output.detach().cpu().permute(0,2,3,1).numpy()\n",
    "plot_p = plot_p.reshape(plot_p.shape[:3])\n",
    "if plot_x.shape[0] == 1:\n",
    "    axes = [axes]\n",
    "for im, mask, pred, (ax_img, ax_mask, ax_pred, ax_round) in zip(plot_x[indeces], plot_y[indeces], plot_p[indeces], axes):\n",
    "    ax_img.imshow(im)\n",
    "    ax_mask.imshow(mask)\n",
    "    ax_pred.imshow(pred)\n",
    "    ax_round.imshow(np.array(pred > 0.5,dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd300d72-59f8-49d4-b607-bd24c043c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('weights_5_112.pkl', 'wb') as f:\n",
    "    pickle.dump(model.state_dict(), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ca848-5bb1-47c1-98e4-2a7f6698d3ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gen_mask(lx, cx, rx, size):\n",
    "    mask = np.ones(size)\n",
    "    half_size = size // 2\n",
    "    if rx is not None:\n",
    "        ls = np.linspace(1, 0, (cx + half_size) - (rx - half_size))\n",
    "        mask[-ls.shape[0]:] = ls\n",
    "        \n",
    "    if lx is not None:\n",
    "        ls = np.linspace(0, 1, lx + half_size - (cx - half_size))\n",
    "        mask[:ls.shape[0]] = ls\n",
    "    return mask\n",
    "\n",
    "def process_image(model, img, size):\n",
    "    half_size = size // 2\n",
    "    lx = half_size\n",
    "    ty = half_size\n",
    "    rx = img.shape[1] - half_size\n",
    "    by = img.shape[0] - half_size\n",
    "    w = rx - lx\n",
    "    h = by - ty\n",
    "    count_x = w // half_size\n",
    "    count_y = h // half_size\n",
    "    dx = w / count_x\n",
    "    dy = h / count_y\n",
    "\n",
    "    center_x = [lx]\n",
    "    for i in range(1, count_x):\n",
    "        x = lx + int(round(i * dx))\n",
    "        center_x.append(x)\n",
    "    center_x.append(rx)\n",
    "\n",
    "    center_y = [ty]\n",
    "    for i in range(1, count_y):\n",
    "        y = ty + int(round(i * dy))\n",
    "        center_y.append(y)\n",
    "    center_y.append(by)\n",
    "\n",
    "    tiles = []\n",
    "    for cy in center_y:\n",
    "        for cx in center_x:\n",
    "            tiles.append(img[cy - half_size:cy + half_size, cx - half_size:cx + half_size, :])\n",
    "\n",
    "    QUOTA = 1024 * 1024\n",
    "    batch_size = QUOTA // size // size\n",
    "    \n",
    "    tiles = np.array(tiles)\n",
    "    outputs = []\n",
    "    for i in range(0, tiles.shape[0], batch_size):\n",
    "        x = torch.tensor(tiles[i:i+batch_size], dtype=torch.float, device=device)/255\n",
    "        x = x.permute(0, 3,1,2)\n",
    "        output = model(x)\n",
    "        outputs.append(output.detach().cpu().numpy())\n",
    "\n",
    "    outputs = np.vstack(outputs)\n",
    "    # res = np.zeros(img.shape[:2], dtype=np.float)\n",
    "    tile = 0\n",
    "    lines = []\n",
    "    for line_num, cy in enumerate(center_y):\n",
    "        line = np.zeros((size, img.shape[1]))\n",
    "        for col_num, cx in enumerate(center_x):\n",
    "            prev_col = col_num - 1\n",
    "            lx = None\n",
    "            rx = None\n",
    "            if prev_col >= 0:\n",
    "                lx = center_x[prev_col]\n",
    "            next_col = col_num + 1\n",
    "            if next_col < len(center_x):\n",
    "                rx = center_x[next_col]\n",
    "            mask = gen_mask(lx, cx, rx, size)\n",
    "            mask = mask.reshape((1,size))\n",
    "            output = outputs[tile] * mask\n",
    "            line[:, cx - half_size:cx + half_size] = output\n",
    "            tile += 1\n",
    "        lines.append(line)\n",
    "\n",
    "    res = np.zeros(img.shape[:2], dtype=np.float32)\n",
    "    for line_num, cy in enumerate(center_y):\n",
    "        line = lines[line_num]\n",
    "        prev_line = line_num - 1\n",
    "        ly = None\n",
    "        ry = None\n",
    "        if prev_line >= 0:\n",
    "            ly = center_y[prev_line]\n",
    "        next_line = line_num + 1\n",
    "        if next_line < len(center_y):\n",
    "            ry = center_y[next_line]\n",
    "        mask = gen_mask(ly, cy, ry, size)\n",
    "        mask = mask.reshape((size, 1))\n",
    "        res[cy - half_size:cy + half_size, :] = mask*line\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "cnt = len(data)\n",
    "fig, axes = plt.subplots(cnt*3, 1, figsize=(15,10*3*cnt))\n",
    "for i in range(cnt):\n",
    "    res = process_image(model, data[i][0], 256)\n",
    "    mask = np.array(res > 0.5, dtype=np.uint8)\n",
    "    print(f\"train_mask_{i:03d}.png\", BinaryF1Score()(torch.tensor(data[i][1]), torch.tensor(mask)).item())\n",
    "    axes[3*i].imshow(data[i][0])\n",
    "    axes[3*i + 1].imshow(data[i][1])\n",
    "    axes[3*i + 2].imshow(np.array(mask>0, dtype=np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd9c66-f9e7-4d70-8537-fe3a8874df21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "test_data = []\n",
    "files = glob('datasets/images/test_image_*.png')\n",
    "files.sort()\n",
    "for im_file in files:\n",
    "    name = os.path.basename(im_file)\n",
    "    im_cv = np.array(Image.open(im_file))\n",
    "    if im_cv.shape[2] != 3:\n",
    "        im_cv = im_cv[:,:,:3]\n",
    "    test_data.append((name, im_cv))\n",
    "\n",
    "cnt = len(test_data)\n",
    "fig, axes = plt.subplots(cnt, 2, figsize=(15,7*cnt))\n",
    "for i in range(cnt):\n",
    "    res = process_image(model, test_data[i][1], 512)\n",
    "    mask = np.array(res > 0.5, dtype=np.uint8)\n",
    "    axes[i][0].imshow(test_data[i][1])\n",
    "    Image.fromarray(mask).save(f'result/test_mask_{i:03d}.png')\n",
    "    axes[i][1].imshow(np.array(mask>0, dtype=np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
